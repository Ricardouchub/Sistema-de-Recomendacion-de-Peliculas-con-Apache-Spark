# üé¨ Sistema de Recomendaci√≥n de Pel√≠culas con Apache Spark

Este proyecto implementa un sistema de recomendaci√≥n de pel√≠culas utilizando **Apache Spark** y su librer√≠a de Machine Learning, **MLlib**. El objetivo es procesar un gran conjunto de datos de calificaciones de pel√≠culas para entrenar un modelo de filtrado colaborativo capaz de generar recomendaciones personalizadas para los usuarios.

Todo el proceso, desde la carga de datos hasta el entrenamiento y la evaluaci√≥n del modelo, se realiza en un entorno de **Google Colab**, demostrando la capacidad de Spark para manejar y analizar datasets a gran escala.



## üìä Dataset Utilizado

Se utiliz√≥ el dataset **MovieLens 32M**, una colecci√≥n estable y reconocida para benchmarks de sistemas de recomendaci√≥n.

* **Calificaciones:** 32 millones de ratings.
* **Pel√≠culas:** 87,585 pel√≠culas.
* **Usuarios:** 200,948 usuarios.
* **Fuente:** [GroupLens - MovieLens 32M Dataset](https://grouplens.org/datasets/movielens/32m/)

## ‚öôÔ∏è Tecnolog√≠as y Librer√≠as

* **Procesamiento de Datos:** Apache Spark (PySpark)
* **Machine Learning:** Spark MLlib (Algoritmo ALS)
* **An√°lisis y Manipulaci√≥n:** Spark SQL, DataFrames
* **Visualizaci√≥n:** Matplotlib & Seaborn
* **Entorno de Ejecuci√≥n:** Google Colab

---

## üöÄ Flujo de Trabajo del Proyecto

El proyecto se estructura en los siguientes pasos clave:

### 1. Configuraci√≥n del Entorno
Instalaci√≥n de PySpark y configuraci√≥n de una `SparkSession` en Google Colab, asignando memoria suficiente para manejar el dataset.

### 2. An√°lisis Exploratorio de Datos (EDA)
Antes de entrenar el modelo, se realiz√≥ un an√°lisis profundo para entender la naturaleza de los datos:
* **Estad√≠sticas Descriptivas:** An√°lisis de la distribuci√≥n de las calificaciones (`ratings`).
* **An√°lisis de Popularidad:** Identificaci√≥n de las pel√≠culas m√°s calificadas y los usuarios m√°s activos.
* **An√°lisis por G√©nero:** Exploraci√≥n de los g√©neros m√°s comunes en el dataset.
* **Visualizaciones:** Creaci√≥n de gr√°ficos para ilustrar la distribuci√≥n de ratings, la frecuencia de g√©neros y la actividad a lo largo del tiempo.

### 3. Preparaci√≥n de Datos
* Limpieza de datos para eliminar valores nulos.
* Conversi√≥n de tipos de datos para asegurar la compatibilidad con el modelo.
* Divisi√≥n del dataset en un conjunto de **entrenamiento (80%)** y uno de **prueba (20%)**.

### 4. Entrenamiento del Modelo de Machine Learning
Se utiliz√≥ el algoritmo de **Alternating Least Squares (ALS)** de Spark MLlib para entrenar el modelo de recomendaci√≥n. ALS es un m√©todo de filtrado colaborativo basado en factorizaci√≥n de matrices que aprende "factores latentes" para cada usuario y pel√≠cula.

### 5. Evaluaci√≥n del Modelo
El rendimiento del modelo se evalu√≥ en el conjunto de prueba utilizando la m√©trica de **Error Cuadr√°tico Medio (RMSE)**. Un RMSE bajo indica que las predicciones de calificaci√≥n del modelo son cercanas a las calificaciones reales de los usuarios.

### 6. Generaci√≥n de Recomendaciones y Pruebas Adicionales
Una vez entrenado y evaluado, el modelo se utiliz√≥ para:
* **Generar las 10 mejores recomendaciones** para un usuario espec√≠fico.
* **Encontrar pel√≠culas similares** a una pel√≠cula dada, bas√°ndose en la similitud de sus factores latentes (el "ADN" de la pel√≠cula).

---

## üíª ¬øC√≥mo Ejecutar este Proyecto?

1.  Clona este repositorio en tu m√°quina local.
2.  Sube el archivo `.ipynb` a tu Google Colab.
3.  Ejecuta las celdas en orden. El notebook est√° dise√±ado para instalar todas las dependencias y descargar el dataset autom√°ticamente.

## ‚ú® Resultados y Conclusiones

Este proyecto demuestra un pipeline completo de Machine Learning con Big Data:
* Se manejaron y procesaron con √©xito m√°s de 32 millones de registros.
* El an√°lisis exploratorio revel√≥ patrones interesantes sobre la distribuci√≥n de g√©neros y la actividad de los usuarios.
* El modelo ALS entrenado logr√≥ un **RMSE** competitivo, demostrando su capacidad para predecir calificaciones con una precisi√≥n razonable.
* El sistema final es capaz de generar recomendaciones personalizadas y encontrar pel√≠culas similares, validando la efectividad del modelo.

Este es un excelente ejemplo pr√°ctico del poder de Apache Spark para construir sistemas de recomendaci√≥n escalables y de alto rendimiento.

---

Creado por **[¬°Aqu√≠ va tu Nombre!]** - [Tu Perfil de GitHub](https://github.com/tu_usuario)